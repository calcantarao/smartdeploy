{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92192f40-4faa-471d-a8a6-6d3620282766",
   "metadata": {
    "papermill": {
     "duration": 0.002008,
     "end_time": "2022-08-22T18:50:53.098161",
     "exception": false,
     "start_time": "2022-08-22T18:50:53.096153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a749fb6f-21d3-4703-bbfa-8dd7e21ab8a7",
   "metadata": {
    "papermill": {
     "duration": 0.606169,
     "end_time": "2022-08-22T18:50:53.706779",
     "exception": false,
     "start_time": "2022-08-22T18:50:53.100610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df275dc0-3e3c-465f-96c5-b9d89c591c39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54d72d40-008a-4b8e-93c3-a94328154e50",
   "metadata": {
    "papermill": {
     "duration": 2.319384,
     "end_time": "2022-08-22T18:50:56.027550",
     "exception": false,
     "start_time": "2022-08-22T18:50:53.708166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://172.20.0.5:8265\" target=\"_blank\">http://172.20.0.5:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "ClientContext(dashboard_url='172.20.0.5:8265', python_version='3.8.13', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', protocol_version='2022-10-05', _num_clients=1, _context_to_restore=<ray.util.client._ClientContext object at 0x7ff1b6728f10>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray_head = \"ray-head\"\n",
    "ray.init(address=f'ray://{ray_head}:10001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4128996d-fda4-459f-b549-5043a2ed8ab4",
   "metadata": {
    "papermill": {
     "duration": 1.928074,
     "end_time": "2022-08-22T18:50:57.957143",
     "exception": false,
     "start_time": "2022-08-22T18:50:56.029069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ServeController pid=807)\u001b[0m INFO 2023-03-21 08:18:22,812 controller 807 http_state.py:129 - Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:UGoFTJ:SERVE_PROXY_ACTOR-6295723a3edf21836f951a4d8d2a0a76ea90155e233d6051c6ab30de' on node '6295723a3edf21836f951a4d8d2a0a76ea90155e233d6051c6ab30de' listening on '0.0.0.0:5010'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.serve._private.client.ServeControllerClient at 0x7ff2487e1bb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m INFO:     Started server process [870]\n"
     ]
    }
   ],
   "source": [
    "serve.start(detached=False, http_options={'host':\"0.0.0.0\", 'port':5010})\n",
    "serve.start(detached=True, http_options={'host':\"0.0.0.0\", 'port':5010})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca77de5-b6d2-4bd5-987c-da6dfe1439a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"http://{ray_head}:5010\")\n",
    "    #response.raise_for_status()\n",
    "    print(\"Modelo esta desplegado\")\n",
    "    #serve.shutdown()\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Modelo no esta desplegado. \", e)\n",
    "    print(\"Desplegando el modelo:\")\n",
    "    serve.start(detached=True, http_options={'host':\"0.0.0.0\", 'port':5010}) # En produccion, ver bien el puerto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a71aab-0d9d-430e-8c5f-77b066932d20",
   "metadata": {},
   "source": [
    "## Server version 2: Ray + FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33cb415-61a4-4004-b652-12825eb2e3df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.95.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastapi\n",
    "\n",
    "fastapi.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a21d2f-f9ef-4b27-a76b-d92f7da3a128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new client HTTP config differs from the existing one in the following fields: ['host', 'port', 'location']. The new HTTP config is ignored.\n",
      "\u001b[2m\u001b[36m(ServeController pid=807)\u001b[0m INFO 2023-03-21 08:29:02,806 controller 807 deployment_state.py:1214 - Stopping 1 replicas of deployment 'LeafDeployment' with outdated versions.\n",
      "\u001b[2m\u001b[36m(ServeController pid=807)\u001b[0m INFO 2023-03-21 08:29:04,963 controller 807 deployment_state.py:1310 - Adding 1 replica to deployment 'LeafDeployment'.\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m Exception in 'lifespan' protocol\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/uvicorn/lifespan/on.py\", line 86, in main\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m     await app(scope, self.receive, self.send)\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/uvicorn/middleware/proxy_headers.py\", line 78, in __call__\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m     return await self.app(scope, receive, send)\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/fastapi/applications.py\", line 270, in __call__\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m     await super().__call__(scope, receive, send)\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/starlette/applications.py\", line 124, in __call__\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m     await self.middleware_stack(scope, receive, send)\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m TypeError: 'NoneType' object is not callable\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m Application startup failed. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayServeSyncHandle(deployment='LeafDeployment')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "from fastapi import FastAPI, Query\n",
    "from pydantic import BaseModel#, Field\n",
    "from fastapi.responses import HTMLResponse\n",
    "from fastapi.responses import RedirectResponse\n",
    "\n",
    "\n",
    "class Input(BaseModel):\n",
    "    specimen_number: float = Query(..., gt=0, example=1)\n",
    "    eccentricity: float = Query(..., gt=0, example=0.86224)\n",
    "    aspect_ratio: float = Query(..., gt=0, example=2.0735)\n",
    "    elongation: float = Query(..., gt=0, example=0.52269)\n",
    "    solidity: float = Query(..., gt=0, example=0.98686)\n",
    "    stochastic_convexity: float = Query(..., gt=0, example=0.99474)\n",
    "    isoperimetric_factor: float = Query(..., gt=0, example=0.70529)\n",
    "    maximal_indentation_depth: float = Query(..., gt=0, example=0.010097)\n",
    "    lobedness: float = Query(..., gt=0, example=0.018554)\n",
    "    average_intensity: float = Query(..., gt=0, example=0.041404)\n",
    "    average_contrast: float = Query(..., gt=0, example=0.12163)\n",
    "    smoothness: float = Query(..., gt=0, example=0.014579)\n",
    "    third_moment: float = Query(..., gt=0, example=0.0048689)\n",
    "    uniformity: float = Query(..., gt=0, example=0.00027608)\n",
    "    entropy: float = Query(..., gt=0, example=0.9458)\n",
    "\n",
    "\n",
    "app = FastAPI(title='Predictor API',\n",
    "              description='Pipeline online inference')\n",
    "\n",
    "\n",
    "@serve.deployment()\n",
    "@serve.ingress(app)\n",
    "# @serve.deployment()\n",
    "class LeafDeployment:\n",
    "    def __init__(self):\n",
    "        model_name = \"extratree\"\n",
    "        model_stage = \"Production\"\n",
    "        self.predictor = mlflow.sklearn.load_model(\n",
    "                                model_uri=f\"models:/{model_name}/{model_stage}\")\n",
    "        self.predictor2 = mlflow.sklearn.load_model(\n",
    "                                model_uri=f\"models:/{model_name}/6\")\n",
    "        self.predictor3 = mlflow.sklearn.load_model(\n",
    "                                model_uri=f\"models:/{model_name}/7\")\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        with mlflow.start_run(run_name='preprocessing') as mlrun:\n",
    "            # Some preprocessing steps here\n",
    "            # df = pd.read_csv(filename)\n",
    "            df_cleaned = df.loc[:, df.columns != 'specimen_number'].copy()\n",
    "            df_cleaned[df_cleaned.columns] = df_cleaned[df_cleaned.columns].astype(float)\n",
    "            df_cleaned.to_csv('preprocessed_data.csv', index=False)\n",
    "            mlflow.log_artifact('preprocessed_data.csv')\n",
    "\n",
    "            # logging\n",
    "            mlflow.log_param(key='n_samples', value=len(df_cleaned))\n",
    "            mlflow.log_param(key='n_features', value=len(df_cleaned.columns))\n",
    "\n",
    "            return df_cleaned\n",
    "\n",
    "    @app.get('/', include_in_schema=False)\n",
    "    async def docs_redirect(self):\n",
    "        return RedirectResponse(url='/docs')\n",
    "\n",
    "    @app.post(\"/predict\",\n",
    "         tags=['Predictor 1 por default'],\n",
    "         summary=\"Usa el modelo 1 para la predicción\")\n",
    "    def call(self, request: Input):\n",
    "    # async def __call__(self, request):\n",
    "        # data = await request.json()\n",
    "        data = request.__dict__\n",
    "        data = pd.json_normalize(data)\n",
    "        preprocessed = self.preprocessing(data)\n",
    "        result = self.predictor.predict(preprocessed)\n",
    "        return result\n",
    "    \n",
    "    @app.post(\"/model2\",\n",
    "         tags=['Predictor 2'],\n",
    "         summary=\"Usa el modelo 2 para la predicción\")\n",
    "    def call(self, request: Input):\n",
    "    # async def __call__(self, request):\n",
    "        # data = await request.json()\n",
    "        data = request.__dict__\n",
    "        data = pd.json_normalize(data)\n",
    "        preprocessed = self.preprocessing(data)\n",
    "        result = self.predictor2.predict(preprocessed)\n",
    "        return result\n",
    "    \n",
    "    @app.post(\"/model3\",\n",
    "         tags=['Predictor 3'],\n",
    "         summary=\"Usa el modelo 3 para la predicción\")\n",
    "    def call(self, request: Input):\n",
    "\n",
    "        # data = await request.json()\n",
    "        data = request.__dict__\n",
    "        data = pd.json_normalize(data)\n",
    "        preprocessed = self.preprocessing(data)\n",
    "        result = self.predictor3.predict(preprocessed)\n",
    "        return result\n",
    "    \n",
    "    @app.post(\"/model_voting\",\n",
    "         tags=['Voting method'],\n",
    "         summary=\"Calcula la moda de las predicciones\")\n",
    "    def call(self, request: Input):\n",
    "        from scipy import stats\n",
    "        \n",
    "        data = request.__dict__\n",
    "        data = pd.json_normalize(data)\n",
    "        preprocessed = self.preprocessing(data)\n",
    "        predicts = [self.predictor.predict(preprocessed),\n",
    "                   self.predictor2.predict(preprocessed),\n",
    "                   self.predictor3.predict(preprocessed)]\n",
    "        result = stats.mode(predicts, keepdims=True).mode[0]\n",
    "        return result\n",
    "    \n",
    "    @app.post(\"/checker_integrity_model\",\n",
    "         tags=['Checker Integrity + model'],\n",
    "         summary=\"Ejecuta el checker de integridad y luego el modelo\")\n",
    "    def call(self, request: Input):\n",
    "        from scipy import stats\n",
    "        \n",
    "        data = request.__dict__\n",
    "        if data['entropy'] >= 10:\n",
    "            return -1\n",
    "        data = pd.json_normalize(data)\n",
    "        preprocessed = self.preprocessing(data)\n",
    "        result = self.predictor3.predict(preprocessed)\n",
    "        return result\n",
    "        \n",
    "# LeafDeployment.deploy()\n",
    "serve.run(LeafDeployment.bind())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db597bc0-ecd1-49fc-b88e-b4f5f26413aa",
   "metadata": {},
   "source": [
    "# Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "786f74b3-6ce0-4c57-a06e-75e63997ae45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'specimen_number': 1,\n",
       "  'eccentricity': 0.86224,\n",
       "  'aspect_ratio': 2.0735,\n",
       "  'elongation': 0.52269,\n",
       "  'solidity': 0.98686,\n",
       "  'stochastic_convexity': 0.99474,\n",
       "  'isoperimetric_factor': 0.70529,\n",
       "  'maximal_indentation_depth': 0.010097,\n",
       "  'lobedness': 0.018554,\n",
       "  'average_intensity': 0.041404,\n",
       "  'average_contrast': 0.12163,\n",
       "  'smoothness': 0.014579,\n",
       "  'third_moment': 0.0048689,\n",
       "  'uniformity': 0.00027608,\n",
       "  'entropy': 0.9458}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "filename = \"artifacts/X_inference.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "# request = df.head(1).to_dict('list')\n",
    "request = df.head(1).to_dict('records')\n",
    "request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1f1f60-d05a-4915-aaf7-0f7a8e473d19",
   "metadata": {},
   "source": [
    "## Llamar al modelo 1, por default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f4011d3-1743-4c95-9236-e929d5f5130f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m ERROR 2023-03-21 08:29:26,842 LeafDeployment LeafDeployment#lKfgOl replica.py:461 - Request failed due to TypeError:\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/serve/_private/replica.py\", line 443, in invoke_single\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m     result = await method_to_call(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/serve/api.py\", line 222, in __call__\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/fastapi/applications.py\", line 270, in __call__\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m     await super().__call__(scope, receive, send)\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/starlette/applications.py\", line 124, in __call__\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m     await self.middleware_stack(scope, receive, send)\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m TypeError: 'NoneType' object is not callable\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1256)\u001b[0m INFO 2023-03-21 08:29:26,843 LeafDeployment LeafDeployment#lKfgOl replica.py:505 - HANDLE __call__ ERROR 1.1ms\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;31m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m             \u001b[0;31m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRequestsJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m INFO 2023-03-21 08:29:26,845 http_proxy 172.20.0.5 http_proxy.py:361 - POST / 500 6.9ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m Task exception was never retrieved\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m future: <Task finished name='Task-24' coro=<_wrap_awaitable() done, defined at /home/ray/anaconda3/lib/python3.8/asyncio/tasks.py:688> exception=RayTaskError(TypeError)(TypeError(\"'NoneType' object is not callable\"))>\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/asyncio/tasks.py\", line 695, in _wrap_awaitable\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m     return (yield from awaitable.__await__())\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::ServeReplica:LeafDeployment.handle_request()\u001b[39m (pid=1256, ip=172.20.0.5)\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/serve/_private/utils.py\", line 238, in wrap_to_ray_error\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m     raise exception\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/serve/_private/replica.py\", line 443, in invoke_single\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m     result = await method_to_call(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/serve/api.py\", line 222, in __call__\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/fastapi/applications.py\", line 270, in __call__\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m     await super().__call__(scope, receive, send)\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/starlette/applications.py\", line 124, in __call__\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m     await self.middleware_stack(scope, receive, send)\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=870)\u001b[0m TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# response = requests.post(\"http://0.0.0.0:5010/predict\", json=request[0])\n",
    "response = requests.post(\"http://ray-head:5010/predict\", json=request[0])\n",
    "# response = requests.post(\"http://ray-head:5010/LeafDeployment\", json=request)\n",
    "result = response.json()[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f9812b-757a-4fd5-be0d-a3a8e5fd60c6",
   "metadata": {},
   "source": [
    "## Llamar al modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4959c669-e3a8-45d0-b253-bcded4d92b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.97 ms, sys: 699 µs, total: 10.7 ms\n",
      "Wall time: 98.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=341)\u001b[0m INFO 2022-11-08 10:19:24,620 http_proxy 172.22.0.4 http_proxy.py:315 - POST / 200 94.8ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=757)\u001b[0m INFO 2022-11-08 10:19:24,618 LeafDeployment LeafDeployment#tamUxz replica.py:505 - HANDLE __call__ OK 90.2ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = requests.post(\"http://ray-head:5010/model2\", json=request[0])\n",
    "# response = requests.post(\"http://ray-head:5010/LeafDeployment\", json=request)\n",
    "result = response.json()[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0fa7f7-4162-4f43-9141-8994226f868e",
   "metadata": {},
   "source": [
    "## Llamar al model_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f099172-b87e-476a-a2c7-952e877c09ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.25 ms, sys: 9.15 ms, total: 14.4 ms\n",
      "Wall time: 167 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=341)\u001b[0m INFO 2022-11-08 11:42:53,742 http_proxy 172.22.0.4 http_proxy.py:315 - POST / 200 162.7ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=2305)\u001b[0m INFO 2022-11-08 11:42:53,740 LeafDeployment LeafDeployment#FytfAS replica.py:505 - HANDLE __call__ OK 159.1ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=341)\u001b[0m INFO 2022-11-08 11:43:41,085 http_proxy 172.22.0.4 http_proxy.py:315 - POST / 200 112.0ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=2305)\u001b[0m INFO 2022-11-08 11:43:41,083 LeafDeployment LeafDeployment#FytfAS replica.py:505 - HANDLE __call__ OK 107.9ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = requests.post(\"http://ray-head:5010/model_voting\", json=request[0])\n",
    "result = response.json()[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19528f90-2ec4-4286-9d99-4ff3a7e9c1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.38681,
   "end_time": "2022-08-22T18:51:04.235975",
   "environment_variables": {},
   "exception": null,
   "input_path": "serving.ipynb",
   "output_path": "serving.ipynb",
   "parameters": {},
   "start_time": "2022-08-22T18:50:51.849165",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
