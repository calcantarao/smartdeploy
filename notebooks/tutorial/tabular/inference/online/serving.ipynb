{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92192f40-4faa-471d-a8a6-6d3620282766",
   "metadata": {
    "papermill": {
     "duration": 0.002008,
     "end_time": "2022-08-22T18:50:53.098161",
     "exception": false,
     "start_time": "2022-08-22T18:50:53.096153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a749fb6f-21d3-4703-bbfa-8dd7e21ab8a7",
   "metadata": {
    "papermill": {
     "duration": 0.606169,
     "end_time": "2022-08-22T18:50:53.706779",
     "exception": false,
     "start_time": "2022-08-22T18:50:53.100610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df275dc0-3e3c-465f-96c5-b9d89c591c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.8\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d72d40-008a-4b8e-93c3-a94328154e50",
   "metadata": {
    "papermill": {
     "duration": 2.319384,
     "end_time": "2022-08-22T18:50:56.027550",
     "exception": false,
     "start_time": "2022-08-22T18:50:53.708166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.init(address='ray://ray-head:10001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128996d-fda4-459f-b549-5043a2ed8ab4",
   "metadata": {
    "papermill": {
     "duration": 1.928074,
     "end_time": "2022-08-22T18:50:57.957143",
     "exception": false,
     "start_time": "2022-08-22T18:50:56.029069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ServeController pid=317)\u001b[0m INFO 2023-01-06 08:38:39,253 controller 317 http_state.py:129 - Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:ibRHty:SERVE_PROXY_ACTOR-fbc3c0e34b760004e6910028d7da6776416926f68ffed9208ad8cde6' on node 'fbc3c0e34b760004e6910028d7da6776416926f68ffed9208ad8cde6' listening on '0.0.0.0:5010'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.serve._private.client.ServeControllerClient at 0x7f592ab94580>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=345)\u001b[0m INFO:     Started server process [345]\n"
     ]
    }
   ],
   "source": [
    "serve.start(detached=False, http_options={'host':\"0.0.0.0\", 'port':5010})\n",
    "# serve.start(http_options={'host':\"0.0.0.0\", 'port':5010})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a71aab-0d9d-430e-8c5f-77b066932d20",
   "metadata": {},
   "source": [
    "## Server version 2: Ray + FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33cb415-61a4-4004-b652-12825eb2e3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.88.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastapi\n",
    "\n",
    "fastapi.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a21d2f-f9ef-4b27-a76b-d92f7da3a128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new client HTTP config differs from the existing one in the following fields: ['host', 'port', 'location']. The new HTTP config is ignored.\n",
      "\u001b[2m\u001b[36m(ServeController pid=1682)\u001b[0m INFO 2022-12-28 14:53:30,563 controller 1682 deployment_state.py:1310 - Adding 1 replica to deployment 'LeafDeployment'.\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1840)\u001b[0m /opt/conda/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeClassifier from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1840)\u001b[0m https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1840)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1840)\u001b[0m /opt/conda/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesClassifier from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1840)\u001b[0m https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1840)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayServeSyncHandle(deployment='LeafDeployment')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel, Field\n",
    "from fastapi.responses import HTMLResponse\n",
    "from fastapi.responses import RedirectResponse\n",
    "\n",
    "\n",
    "class Input(BaseModel):\n",
    "    specimen_number: float = Field(..., gt=0, example=1)\n",
    "    eccentricity: float = Field(..., gt=0, example=0.86224)\n",
    "    aspect_ratio: float = Field(..., gt=0, example=2.0735)\n",
    "    elongation: float = Field(..., gt=0, example=0.52269)\n",
    "    solidity: float = Field(..., gt=0, example=0.98686)\n",
    "    stochastic_convexity: float = Field(..., gt=0, example=0.99474)\n",
    "    isoperimetric_factor: float = Field(..., gt=0, example=0.70529)\n",
    "    maximal_indentation_depth: float = Field(..., gt=0, example=0.010097)\n",
    "    lobedness: float = Field(..., gt=0, example=0.018554)\n",
    "    average_intensity: float = Field(..., gt=0, example=0.041404)\n",
    "    average_contrast: float = Field(..., gt=0, example=0.12163)\n",
    "    smoothness: float = Field(..., gt=0, example=0.014579)\n",
    "    third_moment: float = Field(..., gt=0, example=0.0048689)\n",
    "    uniformity: float = Field(..., gt=0, example=0.00027608)\n",
    "    entropy: float = Field(..., gt=0, example=0.9458)\n",
    "\n",
    "\n",
    "app = FastAPI(title='Predictor API',\n",
    "              description='Pipeline online inference')\n",
    "\n",
    "\n",
    "@serve.deployment()\n",
    "@serve.ingress(app)\n",
    "# @serve.deployment()\n",
    "class LeafDeployment:\n",
    "    def __init__(self):\n",
    "        model_name = \"extratree\"\n",
    "        model_stage = \"Production\"\n",
    "        self.predictor = mlflow.sklearn.load_model(\n",
    "                                model_uri=f\"models:/{model_name}/{model_stage}\")\n",
    "        self.predictor2 = mlflow.sklearn.load_model(\n",
    "                                model_uri=f\"models:/{model_name}/14\")\n",
    "        self.predictor3 = mlflow.sklearn.load_model(\n",
    "                                model_uri=f\"models:/{model_name}/13\")\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        with mlflow.start_run(run_name='preprocessing') as mlrun:\n",
    "            # Some preprocessing steps here\n",
    "            # df = pd.read_csv(filename)\n",
    "            df_cleaned = df.loc[:, df.columns != 'specimen_number'].copy()\n",
    "            df_cleaned[df_cleaned.columns] = df_cleaned[df_cleaned.columns].astype(float)\n",
    "            df_cleaned.to_csv('preprocessed_data.csv', index=False)\n",
    "            mlflow.log_artifact('preprocessed_data.csv')\n",
    "\n",
    "            # logging\n",
    "            mlflow.log_param(key='n_samples', value=len(df_cleaned))\n",
    "            mlflow.log_param(key='n_features', value=len(df_cleaned.columns))\n",
    "\n",
    "            return df_cleaned\n",
    "\n",
    "    @app.get('/', include_in_schema=False)\n",
    "    async def docs_redirect(self):\n",
    "        return RedirectResponse(url='/docs')\n",
    "\n",
    "    @app.post(\"/predict\",\n",
    "         tags=['Predictor 1 por default'],\n",
    "         summary=\"Usa el modelo 1 para la predicción\")\n",
    "    def call(self, request: Input):\n",
    "    # async def __call__(self, request):\n",
    "        # data = await request.json()\n",
    "        data = request.__dict__\n",
    "        data = pd.json_normalize(data)\n",
    "        preprocessed = self.preprocessing(data)\n",
    "        result = self.predictor.predict(preprocessed)\n",
    "        return result\n",
    "    \n",
    "    @app.post(\"/model2\",\n",
    "         tags=['Predictor 2'],\n",
    "         summary=\"Usa el modelo 2 para la predicción\")\n",
    "    def call(self, request: Input):\n",
    "    # async def __call__(self, request):\n",
    "        # data = await request.json()\n",
    "        data = request.__dict__\n",
    "        data = pd.json_normalize(data)\n",
    "        preprocessed = self.preprocessing(data)\n",
    "        result = self.predictor2.predict(preprocessed)\n",
    "        return result\n",
    "    \n",
    "    @app.post(\"/model3\",\n",
    "         tags=['Predictor 3'],\n",
    "         summary=\"Usa el modelo 3 para la predicción\")\n",
    "    def call(self, request: Input):\n",
    "\n",
    "        # data = await request.json()\n",
    "        data = request.__dict__\n",
    "        data = pd.json_normalize(data)\n",
    "        preprocessed = self.preprocessing(data)\n",
    "        result = self.predictor3.predict(preprocessed)\n",
    "        return result\n",
    "    \n",
    "    @app.post(\"/model_voting\",\n",
    "         tags=['Voting method'],\n",
    "         summary=\"Calcula la moda de las predicciones\")\n",
    "    def call(self, request: Input):\n",
    "        from scipy import stats\n",
    "        \n",
    "        data = request.__dict__\n",
    "        data = pd.json_normalize(data)\n",
    "        preprocessed = self.preprocessing(data)\n",
    "        predicts = [self.predictor.predict(preprocessed),\n",
    "                   self.predictor2.predict(preprocessed),\n",
    "                   self.predictor3.predict(preprocessed)]\n",
    "        result = stats.mode(predicts, keepdims=True).mode[0]\n",
    "        return result\n",
    "    \n",
    "    @app.post(\"/checker_integrity_model\",\n",
    "         tags=['Checker Integrity + model'],\n",
    "         summary=\"Ejecuta el checker de integridad y luego el modelo\")\n",
    "    def call(self, request: Input):\n",
    "        from scipy import stats\n",
    "        \n",
    "        data = request.__dict__\n",
    "        if data['entropy'] >= 10:\n",
    "            return -1\n",
    "        data = pd.json_normalize(data)\n",
    "        preprocessed = self.preprocessing(data)\n",
    "        result = self.predictor3.predict(preprocessed)\n",
    "        return result\n",
    "        \n",
    "# LeafDeployment.deploy()\n",
    "serve.run(LeafDeployment.bind())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db597bc0-ecd1-49fc-b88e-b4f5f26413aa",
   "metadata": {},
   "source": [
    "# Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "786f74b3-6ce0-4c57-a06e-75e63997ae45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'specimen_number': 1,\n",
       "  'eccentricity': 0.86224,\n",
       "  'aspect_ratio': 2.0735,\n",
       "  'elongation': 0.52269,\n",
       "  'solidity': 0.98686,\n",
       "  'stochastic_convexity': 0.99474,\n",
       "  'isoperimetric_factor': 0.70529,\n",
       "  'maximal_indentation_depth': 0.010097,\n",
       "  'lobedness': 0.018554,\n",
       "  'average_intensity': 0.041404,\n",
       "  'average_contrast': 0.12163,\n",
       "  'smoothness': 0.014579,\n",
       "  'third_moment': 0.0048689,\n",
       "  'uniformity': 0.00027608,\n",
       "  'entropy': 0.9458}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "filename = \"serving/X_inference.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "# request = df.head(1).to_dict('list')\n",
    "request = df.head(1).to_dict('records')\n",
    "request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1f1f60-d05a-4915-aaf7-0f7a8e473d19",
   "metadata": {},
   "source": [
    "## Llamar al modelo 1, por default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f4011d3-1743-4c95-9236-e929d5f5130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.62 ms, sys: 4.35 ms, total: 5.98 ms\n",
      "Wall time: 532 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=1734)\u001b[0m INFO 2022-12-28 14:55:41,997 http_proxy 172.20.0.6 http_proxy.py:315 - POST / 200 528.3ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=1840)\u001b[0m INFO 2022-12-28 14:55:41,995 LeafDeployment LeafDeployment#EHjEeW replica.py:505 - HANDLE __call__ OK 522.6ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = requests.post(\"http://0.0.0.0:5010/predict\", json=request[0])\n",
    "# response = requests.post(\"http://ray-head:5010/predict\", json=request[0])\n",
    "# response = requests.post(\"http://ray-head:5010/LeafDeployment\", json=request)\n",
    "result = response.json()[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f9812b-757a-4fd5-be0d-a3a8e5fd60c6",
   "metadata": {},
   "source": [
    "## Llamar al modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4959c669-e3a8-45d0-b253-bcded4d92b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.97 ms, sys: 699 µs, total: 10.7 ms\n",
      "Wall time: 98.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=341)\u001b[0m INFO 2022-11-08 10:19:24,620 http_proxy 172.22.0.4 http_proxy.py:315 - POST / 200 94.8ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=757)\u001b[0m INFO 2022-11-08 10:19:24,618 LeafDeployment LeafDeployment#tamUxz replica.py:505 - HANDLE __call__ OK 90.2ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = requests.post(\"http://ray-head:5010/model2\", json=request[0])\n",
    "# response = requests.post(\"http://ray-head:5010/LeafDeployment\", json=request)\n",
    "result = response.json()[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0fa7f7-4162-4f43-9141-8994226f868e",
   "metadata": {},
   "source": [
    "## Llamar al model_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f099172-b87e-476a-a2c7-952e877c09ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.25 ms, sys: 9.15 ms, total: 14.4 ms\n",
      "Wall time: 167 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=341)\u001b[0m INFO 2022-11-08 11:42:53,742 http_proxy 172.22.0.4 http_proxy.py:315 - POST / 200 162.7ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=2305)\u001b[0m INFO 2022-11-08 11:42:53,740 LeafDeployment LeafDeployment#FytfAS replica.py:505 - HANDLE __call__ OK 159.1ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=341)\u001b[0m INFO 2022-11-08 11:43:41,085 http_proxy 172.22.0.4 http_proxy.py:315 - POST / 200 112.0ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:LeafDeployment pid=2305)\u001b[0m INFO 2022-11-08 11:43:41,083 LeafDeployment LeafDeployment#FytfAS replica.py:505 - HANDLE __call__ OK 107.9ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = requests.post(\"http://ray-head:5010/model_voting\", json=request[0])\n",
    "result = response.json()[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19528f90-2ec4-4286-9d99-4ff3a7e9c1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.38681,
   "end_time": "2022-08-22T18:51:04.235975",
   "environment_variables": {},
   "exception": null,
   "input_path": "serving.ipynb",
   "output_path": "serving.ipynb",
   "parameters": {},
   "start_time": "2022-08-22T18:50:51.849165",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
